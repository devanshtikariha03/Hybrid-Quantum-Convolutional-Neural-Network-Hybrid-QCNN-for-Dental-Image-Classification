{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import transforms, datasets\nfrom torch.utils.data import DataLoader\n\n# Define a simple model\nclass HybridQCNN(nn.Module):\n    def __init__(self):\n        super(HybridQCNN, self).__init__()\n        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)  # Change 1 to 3 for RGB images\n        self.fc1 = nn.Linear(32 * 32 * 32, 64)  # Adjust the size according to your model\n        self.fc2 = nn.Linear(64, 7)  # 7 classes\n\n    def forward(self, x):\n        x = torch.relu(self.conv1(x))\n        x = x.view(-1, 32 * 32 * 32)  # Flatten\n        x = torch.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x\n\n\n# Initialize the model\nmodel = HybridQCNN()\n\n# Check parameters\nprint(\"Model Parameters:\")\nfor param in model.parameters():\n    print(param.size())\n\n# Define loss and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# Dummy data for testing\ntransform = transforms.Compose([\n    transforms.Resize((32, 32)),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize for RGB images\n])\n\ndataset = datasets.ImageFolder(root='/kaggle/input/dental-radiography', transform=transform)\ndata_loader = DataLoader(dataset, batch_size=16, shuffle=True)\n\n# Training loop (simple example)\nnum_epochs = 1\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n    for images, labels in data_loader:\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item()\n    print(f'Epoch {epoch+1}, Loss: {running_loss/len(data_loader)}')\n\n# Save the trained model\ntorch.save(model.state_dict(), 'model.pth')\nprint(\"Model saved as 'model.pth'\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchvision.transforms as transforms\nfrom PIL import Image\n\n# Define the model to match the saved state dict\nclass HybridQCNN(nn.Module):\n    def __init__(self):\n        super(HybridQCNN, self).__init__()\n        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)  # RGB images\n        self.fc1 = nn.Linear(32 * 32 * 32, 64)  # Adjust according to saved model\n        self.fc2 = nn.Linear(64, 7)  # 7 classes\n\n    def forward(self, x):\n        x = torch.relu(self.conv1(x))\n        x = x.view(-1, 32 * 32 * 32)  # Flatten\n        x = torch.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x\n\n# Define transformations\ntransform = transforms.Compose([\n    transforms.Resize((32, 32)),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize for RGB images\n])\n\n# Load model\nmodel = HybridQCNN()\ntry:\n    model.load_state_dict(torch.load('model.pth'))\n    print(\"Model loaded successfully.\")\nexcept RuntimeError as e:\n    print(f\"Error loading model: {e}\")\nmodel.eval()\n\n# Map labels to symptoms\nsymptoms = [\n    'stumps', 'implant teeth', 'missing teeth', \n    'patches', 'periodontal', 'impacted teeth', \n    'root canals'\n]\n\ndef get_symptom(label):\n    return symptoms[label]\n\ndef classify_image(image_path):\n    # Load the image\n    image = Image.open(image_path).convert(\"RGB\")  # Adjusted to RGB if needed\n    \n    # Apply transformations\n    image = transform(image).unsqueeze(0)  # Add batch dimension\n    \n    # Perform classification\n    with torch.no_grad():\n        outputs = model(image)\n        _, predicted = torch.max(outputs, 1)\n        predicted_label = predicted.item()\n    \n    return predicted_label\n\n# Path to the single image\nimage_path = '/kaggle/input/dentalscan2/52.png'\nlabel = classify_image(image_path)\nsymptom = get_symptom(label)\nprint(f'The image is classified as: {symptom}')\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}